name: Create Infrastructure and Deploy Application

on:
  workflow_dispatch:
    inputs:
      aws_region:
        description: 'AWS Region to deploy to'
        required: true
        type: choice
        options:
          - us-east-1
          - us-east-2
          - us-west-1
          - us-west-2
          - eu-west-1
          - eu-west-2
          - eu-central-1
          - ap-southeast-1
          - ap-southeast-2
          - ap-northeast-1
        default: 'ap-southeast-1'

env:
  AWS_REGION: ${{ github.event.inputs.aws_region }}
  TF_STATE_BUCKET_PREFIX: "hrgoat-tfstate-do-not-delete"
  TF_STATE_KEY: "terraform/state/prod/terraform.tfstate"
  PROJECT_NAME: "hrgoat"
  DB_PASSWORD: "hrportaladmin123"

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    
    outputs:
      app_instance_id: ${{ steps.terraform_outputs.outputs.app_instance_id }}
      rds_endpoint: ${{ steps.terraform_outputs.outputs.rds_endpoint }}
      ecr_repository_name: ${{ steps.terraform_outputs.outputs.ecr_repository_name }}
      tf_state_bucket: ${{ steps.create_bucket.outputs.bucket_name }}
      alb_dns_name: ${{ steps.terraform_outputs.outputs.alb_dns_name }}
      app_alb_url: ${{ steps.terraform_outputs.outputs.app_alb_url }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }} 
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.0.0

    - name: Create unique S3 bucket name for Terraform state
      id: create_bucket
      run: |
        # Generate unique bucket name with epoch timestamp and region
        TIMESTAMP=$(date +%s)
        BUCKET_NAME="${{ env.TF_STATE_BUCKET_PREFIX }}-${{ env.AWS_REGION }}-${TIMESTAMP}"
        echo "bucket_name=${BUCKET_NAME}" >> $GITHUB_OUTPUT
        echo "Using bucket name: ${BUCKET_NAME}"

    - name: Create S3 bucket for Terraform state if it doesn't exist
      run: |
        BUCKET_NAME="${{ steps.create_bucket.outputs.bucket_name }}"
        
        # For us-east-1, don't specify location constraint
        if [ "${{ env.AWS_REGION }}" == "us-east-1" ]; then
          aws s3api head-bucket --bucket ${BUCKET_NAME} 2>/dev/null || \
          aws s3api create-bucket --bucket ${BUCKET_NAME} --region ${{ env.AWS_REGION }}
        else
          aws s3api head-bucket --bucket ${BUCKET_NAME} 2>/dev/null || \
          aws s3api create-bucket --bucket ${BUCKET_NAME} --region ${{ env.AWS_REGION }} \
            --create-bucket-configuration LocationConstraint=${{ env.AWS_REGION }}
        fi
        
        # Enable versioning
        aws s3api put-bucket-versioning --bucket ${BUCKET_NAME} --versioning-configuration Status=Enabled
        
        # Store bucket name in a file that will be stored in S3 for reference by destroy workflow
        echo "BUCKET_NAME=${BUCKET_NAME}" > bucket-name.txt
        echo "REGION=${{ env.AWS_REGION }}" >> bucket-name.txt
        aws s3 cp bucket-name.txt s3://${BUCKET_NAME}/bucket-name.txt

    - name: Terraform Init
      run: |
        cd terraform
        terraform init \
          -backend-config="bucket=${{ steps.create_bucket.outputs.bucket_name }}" \
          -backend-config="key=${{ env.TF_STATE_KEY }}" \
          -backend-config="region=${{ env.AWS_REGION }}"

    - name: Terraform Plan
      run: |
        cd terraform
        terraform plan -var="project_name=${{ env.PROJECT_NAME }}" -var="db_password=${{ env.DB_PASSWORD }}" -var="aws_region=${{ env.AWS_REGION }}" -out=tfplan

    - name: Terraform Apply
      run: |
        cd terraform
        terraform apply -auto-approve tfplan

    - name: Export Terraform Outputs
      id: terraform_outputs
      run: |
        cd terraform
        
        # Display all available outputs for debugging
        echo "All Terraform outputs:"
        terraform output || echo "No outputs found"
        
        # Check if core resources were created by querying AWS directly
        echo "Checking for resources created by Terraform..."
        
        # 1. Get the latest EC2 instance by tag and creation time, excluding terminated instances
        echo "Finding the latest app instance..."
        APP_INSTANCE_ID=$(aws ec2 describe-instances \
          --filters \
            "Name=tag:Name,Values=${{ env.PROJECT_NAME }}-app-instance" \
            "Name=instance-state-name,Values=pending,running" \
          --query "Reservations[*].Instances[*].[InstanceId,LaunchTime]" \
          --output text | sort -k2 -r | head -n1 | awk '{print $1}')
        
        # If not found with primary tag, try project tag
        if [ "$APP_INSTANCE_ID" == "None" ] || [ -z "$APP_INSTANCE_ID" ]; then
          echo "Warning: Could not find app instance with tag Name=${{ env.PROJECT_NAME }}-app-instance"
          # Try to fallback to any instance with our project tag, still filtering for non-terminated
          APP_INSTANCE_ID=$(aws ec2 describe-instances \
            --filters \
              "Name=tag-key,Values=Project" \
              "Name=tag-value,Values=${{ env.PROJECT_NAME }}" \
              "Name=instance-state-name,Values=pending,running" \
            --query "Reservations[*].Instances[*].[InstanceId,LaunchTime]" \
            --output text | sort -k2 -r | head -n1 | awk '{print $1}')
        fi
        
        # Verify the instance is in a valid state
        if [ -n "$APP_INSTANCE_ID" ]; then
          INSTANCE_STATE=$(aws ec2 describe-instances \
            --instance-ids "$APP_INSTANCE_ID" \
            --query "Reservations[0].Instances[0].State.Name" \
            --output text)
          echo "Found EC2 instance ID: $APP_INSTANCE_ID (State: $INSTANCE_STATE)"
        else
          echo "Warning: Could not find any running or pending app instances"
        fi
        
        # 2. Get RDS instance by tag/identifier
        RDS_ENDPOINT=$(aws rds describe-db-instances --db-instance-identifier "${{ env.PROJECT_NAME }}-db" --query "DBInstances[0].Endpoint.Address" --output text 2>/dev/null)
        if [ "$RDS_ENDPOINT" == "None" ] || [ -z "$RDS_ENDPOINT" ]; then
          echo "Warning: Could not find RDS instance with identifier ${{ env.PROJECT_NAME }}-db"
          # Look for any instance with similar name
          RDS_ENDPOINT=$(aws rds describe-db-instances --query "DBInstances[?starts_with(DBInstanceIdentifier, '${{ env.PROJECT_NAME }}')].Endpoint.Address" --output text | head -1)
        fi
        RDS_PORT=$(aws rds describe-db-instances --db-instance-identifier "${{ env.PROJECT_NAME }}-db" --query "DBInstances[0].Endpoint.Port" --output text 2>/dev/null || echo "3306")
        RDS_HOST="${RDS_ENDPOINT}:${RDS_PORT}"
        echo "Found RDS endpoint: $RDS_HOST"
        
        # 3. Check ECR repository
        # We're already using a hardcoded repo name, so this is less critical
        ECR_REPOSITORY_NAME="${{ env.PROJECT_NAME }}-app-repository"
        echo "Using ECR repository: $ECR_REPOSITORY_NAME"
        
        # 4. Check ALB
        ALB_DNS_NAME=$(aws elbv2 describe-load-balancers --names "${{ env.PROJECT_NAME }}-alb" --query "LoadBalancers[0].DNSName" --output text 2>/dev/null)
        if [ "$ALB_DNS_NAME" == "None" ] || [ -z "$ALB_DNS_NAME" ]; then
          echo "Warning: Could not find ALB with name ${{ env.PROJECT_NAME }}-alb"
        fi
        APP_ALB_URL="http://${ALB_DNS_NAME}"
        echo "ALB DNS Name: $ALB_DNS_NAME"
        echo "ALB URL: $APP_ALB_URL"
        
        # Set outputs directly in GitHub's format
        echo "app_instance_id=$APP_INSTANCE_ID" >> $GITHUB_OUTPUT
        echo "rds_endpoint=$RDS_HOST" >> $GITHUB_OUTPUT
        echo "ecr_repository_name=$ECR_REPOSITORY_NAME" >> $GITHUB_OUTPUT
        echo "alb_dns_name=$ALB_DNS_NAME" >> $GITHUB_OUTPUT
        echo "app_alb_url=$APP_ALB_URL" >> $GITHUB_OUTPUT

    - name: Verify Terraform Outputs
      run: |
        echo "Terraform outputs set for next job:"
        echo "APP_INSTANCE_ID = ${{ steps.terraform_outputs.outputs.app_instance_id }}"
        echo "RDS_ENDPOINT = ${{ steps.terraform_outputs.outputs.rds_endpoint }}"
        echo "ECR_REPOSITORY_NAME = ${{ steps.terraform_outputs.outputs.ecr_repository_name }}"
        echo "ALB_DNS_NAME = ${{ steps.terraform_outputs.outputs.alb_dns_name }}"
        echo "APP_ALB_URL = ${{ steps.terraform_outputs.outputs.app_alb_url }}"

  build-and-deploy:
    name: 'Build and Deploy Application'
    needs: terraform
    runs-on: ubuntu-latest
    # Always run this job when terraform completes, as the outputs issue should be fixed now

    env:
      APP_INSTANCE_ID: ${{ needs.terraform.outputs.app_instance_id }}
      RDS_HOST: ${{ needs.terraform.outputs.rds_endpoint }}
      ECR_REPOSITORY_NAME: ${{ needs.terraform.outputs.ecr_repository_name }}
      RDS_USER: admin
      RDS_PASSWORD: hrportaladmin123
      RDS_DATABASE: hrportal
      TF_STATE_BUCKET: ${{ needs.terraform.outputs.tf_state_bucket }}
      ALB_DNS_NAME: ${{ needs.terraform.outputs.alb_dns_name }}
      APP_ALB_URL: ${{ needs.terraform.outputs.app_alb_url }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }} 
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Debug environment variables
      run: |
        echo "ECR Registry: ${{ steps.login-ecr.outputs.registry }}"
        echo "ECR Repository Name: ${{ env.ECR_REPOSITORY_NAME }}"
        if [ -z "${{ env.ECR_REPOSITORY_NAME }}" ]; then
          echo "::error::ECR_REPOSITORY_NAME is empty!"
          exit 1
        fi

    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'

    - name: Build frontend
      run: |
        # Install dependencies with legacy-peer-deps to handle React 19 compatibility
        npm ci --legacy-peer-deps

        # Build frontend to create dist directory
        echo "Building frontend..."
        npm run build
        
        # Verify dist directory was created
        if [ ! -d "./dist" ]; then
          echo "::error::Frontend build failed, dist directory not created"
          exit 1
        fi
        echo "Frontend build successful!"

    - name: Build, tag, and push image to Amazon ECR
      id: build-image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
      run: |
        # Construct the full ECR repository URL using the registry from login step
        FULL_ECR_REPOSITORY="${ECR_REGISTRY}/${{ env.ECR_REPOSITORY_NAME }}"
        echo "Full ECR Repository URL: ${FULL_ECR_REPOSITORY}"
        
        # Build a docker container and push it to ECR using the unified Dockerfile
        docker build -f Dockerfile.unified -t ${FULL_ECR_REPOSITORY}:${{ github.sha }} .
        docker push ${FULL_ECR_REPOSITORY}:${{ github.sha }}
        docker tag ${FULL_ECR_REPOSITORY}:${{ github.sha }} ${FULL_ECR_REPOSITORY}:latest
        docker push ${FULL_ECR_REPOSITORY}:latest
        echo "image=${FULL_ECR_REPOSITORY}:${{ github.sha }}" >> $GITHUB_OUTPUT

    - name: Verify EC2 Instance State
      run: |
        MAX_RETRIES=20  # Maximum attempts (increased from 12)
        INSTANCE_ID="${{ env.APP_INSTANCE_ID }}"  # Instance ID
        REGION="${{ env.AWS_REGION }}"  # AWS region
        COUNT=0
        
        if [ -z "$INSTANCE_ID" ]; then
          echo "::error::No valid EC2 instance ID found. Cannot continue verification."
          exit 1
        fi
        
        echo "Verifying state of EC2 instance: $INSTANCE_ID"

        until [ "$INSTANCE_STATE" == "running" ] || [ "$COUNT" -ge "$MAX_RETRIES" ]; do
            INSTANCE_STATE=$(aws ec2 describe-instances --instance-ids "$INSTANCE_ID" --region "$REGION" --query "Reservations[0].Instances[0].State.Name" --output text)

            if [ "$INSTANCE_STATE" == "running" ]; then
                echo "âœ… EC2 instance $INSTANCE_ID is now in a running state."
                
                # Check if SSM agent is ready by attempting a simple SSM command
                echo "Checking if SSM agent is ready..."
                if aws ssm describe-instance-information --filters "Key=InstanceIds,Values=$INSTANCE_ID" --query "InstanceInformationList[0].PingStatus" --output text | grep -q "Online"; then
                  echo "âœ… SSM agent is online and ready."
                else
                  echo "âš ï¸ SSM agent is not yet reporting as online. Waiting for it to initialize..."
                  # Wait a bit longer for SSM agent to initialize
                  sleep 30
                fi
                break
            fi

            COUNT=$((COUNT+1))
            echo "â³ Attempt $COUNT/$MAX_RETRIES: EC2 instance $INSTANCE_ID is in '$INSTANCE_STATE' state. Waiting..."
            sleep 15  # Increased wait time between checks
        done

        # One final check after all retries
        INSTANCE_STATE=$(aws ec2 describe-instances --instance-ids "$INSTANCE_ID" --region "$REGION" --query "Reservations[0].Instances[0].State.Name" --output text)
        if [ "$INSTANCE_STATE" != "running" ]; then
          echo "::error::EC2 instance $INSTANCE_ID failed to reach running state after $MAX_RETRIES attempts. Current state: $INSTANCE_STATE"
          exit 1
        fi
        
        # Verify the instance has SSM agent properly configured
        echo "Verifying SSM agent on instance $INSTANCE_ID..."
        SSM_STATUS=$(aws ssm describe-instance-information --filters "Key=InstanceIds,Values=$INSTANCE_ID" --query "InstanceInformationList[0].PingStatus" --output text || echo "Unknown")
        
        if [ "$SSM_STATUS" != "Online" ]; then
          echo "::warning::SSM agent on instance $INSTANCE_ID is not reporting as online (status: $SSM_STATUS). Deployment may fail."
          # Don't exit with error, as sometimes SSM can still work even if not reporting online yet
          # Instead, add a delay to give it more time
          echo "Waiting additional time for SSM agent to initialize..."
          sleep 60
        else
          echo "âœ… SSM agent is online and ready to receive commands."
        fi

    - name: Deploy to EC2 via SSM
      run: |
        # Verify we have the required values
        echo "Checking essential parameters:"
        echo "APP_INSTANCE_ID: ${{ env.APP_INSTANCE_ID }}"
        echo "RDS_HOST: ${{ env.RDS_HOST }}"
        
        # Exit if essential parameters are missing
        if [ -z "${{ env.APP_INSTANCE_ID }}" ]; then
          echo "::error::APP_INSTANCE_ID is empty! Cannot continue deployment."
          exit 1
        fi
        
        # Extract RDS hostname from endpoint if available
        DB_HOST=""
        if [ -n "${{ env.RDS_HOST }}" ]; then
          DB_HOST=$(echo "${{ env.RDS_HOST }}" | cut -d: -f1)
        fi
        
        # Print all environment variables
        echo "Environment variables:"
        echo "APP_INSTANCE_ID: ${{ env.APP_INSTANCE_ID }}"
        echo "RDS_HOST: ${{ env.RDS_HOST }}"
        echo "ECR_REPOSITORY_NAME: ${{ env.ECR_REPOSITORY_NAME }}"
        echo "RDS_USER: ${{ env.RDS_USER }}"
        echo "RDS_PASSWORD: ${{ env.RDS_PASSWORD }}"
        
        # Wait for instance to be fully ready
        echo "Checking if instance is ready for deployment..."
        MAX_WAIT=600  # 10 minutes (increased from 5)
        WAIT_TIME=0
        INSTANCE_READY=false
        
        while [ $WAIT_TIME -lt $MAX_WAIT ]; do
          # Check if Docker and AWS CLI are installed and ready
          if aws ssm send-command \
            --instance-ids ${{ env.APP_INSTANCE_ID }} \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=["which docker && which aws && systemctl is-active docker && echo TOOLS_READY || echo TOOLS_NOT_READY"]' \
            --query "Command.CommandId" \
            --output text > /tmp/check_cmd_id 2>&1; then
            
            sleep 10  # Give more time for command to complete
            CHECK_OUTPUT=$(aws ssm get-command-invocation \
              --command-id "$(cat /tmp/check_cmd_id)" \
              --instance-id ${{ env.APP_INSTANCE_ID }} \
              --query "StandardOutputContent" \
              --output text 2>/dev/null || echo "")
            
            if [[ "$CHECK_OUTPUT" == *"TOOLS_READY"* ]]; then
              echo "âœ… Instance is ready for deployment! Docker and AWS CLI are installed."
              INSTANCE_READY=true
              break
            else
              echo "Tools not ready yet. Output: $CHECK_OUTPUT"
            fi
          fi
          
          echo "Waiting for instance to be ready... ($WAIT_TIME/$MAX_WAIT seconds)"
          sleep 15  # Increased wait time between checks
          WAIT_TIME=$((WAIT_TIME + 15))
        done
        
        if [ "$INSTANCE_READY" != "true" ]; then
          echo "::error::Instance did not become ready within $MAX_WAIT seconds. Docker or AWS CLI may not be installed."
          
          # Try to get diagnostic information
          echo "Attempting to get diagnostic information..."
          aws ssm send-command \
            --instance-ids ${{ env.APP_INSTANCE_ID }} \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=["tail -n 50 /var/log/user-data.log || echo No user-data log found"]' \
            --query "Command.CommandId" \
            --output text > /tmp/diag_cmd_id 2>&1 || true
          
          sleep 5
          aws ssm get-command-invocation \
            --command-id "$(cat /tmp/diag_cmd_id)" \
            --instance-id ${{ env.APP_INSTANCE_ID }} \
            --query "StandardOutputContent" \
            --output text 2>/dev/null || echo "Could not retrieve diagnostic logs"
          
          exit 1
        fi
        
        # Pre-deployment verification
        echo "Running pre-deployment verification..."
        VERIFY_CMD=$(aws ssm send-command \
          --instance-ids ${{ env.APP_INSTANCE_ID }} \
          --document-name "AWS-RunShellScript" \
          --parameters 'commands=["echo \"=== Pre-deployment verification ===\"","docker --version","aws --version","systemctl status docker --no-pager | head -10","ls -la /usr/bin/docker /usr/local/bin/aws","echo \"=== Verification complete ===\""]' \
          --query "Command.CommandId" \
          --output text)
        
        sleep 10
        echo "Verification output:"
        aws ssm get-command-invocation \
          --command-id "$VERIFY_CMD" \
          --instance-id ${{ env.APP_INSTANCE_ID }} \
          --query "StandardOutputContent" \
          --output text
        
        # Create commands JSON string for unified server with container escape vulnerabilities
        COMMANDS_JSON='["bash -c \"export PATH=/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:\$PATH && docker stop hrportal || true && docker rm hrportal || true && aws ecr get-login-password --region '"${{ env.AWS_REGION }}"' | docker login --username AWS --password-stdin '"${{ steps.login-ecr.outputs.registry }}"' && docker pull '"${{ steps.build-image.outputs.image }}"' && docker run -d --name hrportal -p 80:8080 -e DB_HOST=\\\"'"$DB_HOST"'\\\" -e DB_USER=\\\"'"${{ env.RDS_USER }}"'\\\" -e DB_PASSWORD=\\\"'"${{ env.RDS_PASSWORD }}"'\\\" -e DB_NAME=\\\"'"${{ env.RDS_DATABASE }}"'\\\" -e PORT=\\\"8080\\\" --privileged --pid=host --cap-add=ALL --security-opt apparmor:unconfined --security-opt seccomp:unconfined -v /var/run/docker.sock:/var/run/docker.sock -v /:/host -e VITE_BASE_URL=\\\"http://localhost\\\" '"${{ steps.build-image.outputs.image }}"' && docker ps | grep hrportal\""]'
        
        echo "Using commands: $COMMANDS_JSON"
        
        # Deploy using SSM with properly formatted JSON parameter and retries
        MAX_ATTEMPTS=3
        CURRENT_ATTEMPT=1
        
        while [ $CURRENT_ATTEMPT -le $MAX_ATTEMPTS ]; do
          echo "Attempt $CURRENT_ATTEMPT to send SSM command to instance ${{ env.APP_INSTANCE_ID }}"
          
          if SSM_OUTPUT=$(aws ssm send-command \
            --instance-ids ${{ env.APP_INSTANCE_ID }} \
            --document-name "AWS-RunShellScript" \
            --parameters commands="$COMMANDS_JSON" \
            --query "Command.CommandId" \
            --output text 2>&1); then
              
            echo "SSM command sent successfully! Command ID: $SSM_OUTPUT"
            COMMAND_ID=$SSM_OUTPUT
            
            # Wait for command to complete
            echo "Waiting for SSM command to complete..."
            # Start with shorter waits, then longer ones
            for WAIT_TIME in 10 20 30 60; do
              # Check command status
              STATUS=$(aws ssm list-commands \
                --command-id $COMMAND_ID \
                --query "Commands[0].Status" \
                --output text)
              
              echo "Command status: $STATUS"
              
              if [ "$STATUS" = "Success" ]; then
                echo "âœ… SSM command executed successfully!"
                
                # Get command output for logging
                aws ssm get-command-invocation \
                  --command-id $COMMAND_ID \
                  --instance-id ${{ env.APP_INSTANCE_ID }} \
                  --query "StandardOutputContent" \
                  --output text
                
                # Command succeeded, exit the loop
                break 2
              elif [ "$STATUS" = "Failed" ]; then
                echo "âŒ SSM command failed, getting error logs:"
                
                # Get error output
                aws ssm get-command-invocation \
                  --command-id $COMMAND_ID \
                  --instance-id ${{ env.APP_INSTANCE_ID }} \
                  --query "StandardErrorContent" \
                  --output text
                
                if [ $CURRENT_ATTEMPT -lt $MAX_ATTEMPTS ]; then
                  echo "Will retry in 60 seconds..."
                  sleep 60
                  break
                else
                  echo "::error::SSM command failed after $MAX_ATTEMPTS attempts"
                  exit 1
                fi
              elif [ "$STATUS" = "Cancelled" ] || [ "$STATUS" = "TimedOut" ]; then
                echo "âš ï¸ SSM command $STATUS"
                if [ $CURRENT_ATTEMPT -lt $MAX_ATTEMPTS ]; then
                  echo "Will retry in 60 seconds..."
                  sleep 60
                  break
                else
                  echo "::error::SSM command $STATUS after $MAX_ATTEMPTS attempts"
                  exit 1
                fi
              else
                echo "Command still in progress, waiting $WAIT_TIME seconds..."
                sleep $WAIT_TIME
              fi
            done
          else
            # Command send failed
            echo "Failed to send SSM command: $SSM_OUTPUT"
            
            if [ $CURRENT_ATTEMPT -lt $MAX_ATTEMPTS ]; then
              echo "Will retry in 60 seconds..."
              sleep 60
            else
              echo "::error::Failed to send SSM command after $MAX_ATTEMPTS attempts"
              exit 1
            fi
          fi
          
          CURRENT_ATTEMPT=$((CURRENT_ATTEMPT + 1))
        done

    - name: Deploy Cortex XDR Agent
      continue-on-error: true
      run: |
        echo "Checking for xdr_install directory and tar.gz file..."
        
        # Debug workspace structure
        echo "Current directory: $(pwd)"
        echo "Listing workspace root content:"
        ls -la
        
        # Initialize error status flag
        XDR_INSTALL_SUCCESS=true
        
        # Check if xdr_install directory exists
        if [ -d "xdr_install" ]; then
          echo "Found xdr_install directory"
          echo "Listing xdr_install content:"
          ls -la xdr_install
          
          # Check for .tar.gz files
          TAR_FILES=$(find xdr_install -name "*.tar.gz" | head -1)
          
          if [ -n "$TAR_FILES" ]; then
            echo "Found tar.gz file: $TAR_FILES"
            
            # Upload the tar.gz file to S3 temporarily for transfer to EC2
            S3_BUCKET="${{ env.TF_STATE_BUCKET }}"
            TAR_FILENAME=$(basename "$TAR_FILES")
            
            # Debug the S3 bucket name
            echo "S3 Bucket: $S3_BUCKET"
            
            # Fallback if TF_STATE_BUCKET is not set
            if [ -z "$S3_BUCKET" ]; then
              echo "TF_STATE_BUCKET not set, falling back to environment value"
              # Get the bucket name from terraform output
              cd terraform
              S3_BUCKET=$(terraform output -raw tf_state_bucket || echo "")
              cd ..
              
              if [ -z "$S3_BUCKET" ]; then
                echo "::warning::Could not determine S3 bucket name for file transfer. XDR installation skipped."
                echo "::notice::XDR Agent installation failed: Could not determine S3 bucket name"
                XDR_INSTALL_SUCCESS=false
              fi
            fi
            
            if [ "$XDR_INSTALL_SUCCESS" = true ]; then
              echo "Using S3 bucket: $S3_BUCKET for XDR installation files"
              
              echo "Uploading $TAR_FILENAME to S3 bucket $S3_BUCKET..."
              aws s3 cp "$TAR_FILES" "s3://$S3_BUCKET/$TAR_FILENAME" || {
                echo "::warning::Failed to upload XDR installation files to S3. XDR installation skipped."
                echo "::notice::XDR Agent installation failed: S3 upload error"
                XDR_INSTALL_SUCCESS=false
              }
              
              if [ "$XDR_INSTALL_SUCCESS" = true ]; then
                # Create a script to handle the XDR installation on the EC2 instance
                echo "Creating XDR installation script..."
                
                # Write script contents line by line to avoid heredoc YAML issues
                echo '#!/bin/bash' > xdr_install.sh
                echo '# Exit on command errors but allow the script to continue' >> xdr_install.sh
                echo 'set +e' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Create the log directory if it doesn'"'"'t exist' >> xdr_install.sh
                echo 'mkdir -p /var/log' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Log file for installation' >> xdr_install.sh
                echo 'LOG_FILE="/var/log/xdr_install.log"' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Detect OS and install dependencies accordingly' >> xdr_install.sh
                echo 'if [ -f /etc/os-release ]; then' >> xdr_install.sh
                echo '  . /etc/os-release' >> xdr_install.sh
                echo '  OS=$ID' >> xdr_install.sh
                echo 'elif [ -f /etc/redhat-release ]; then' >> xdr_install.sh
                echo '  OS="centos"' >> xdr_install.sh
                echo 'else' >> xdr_install.sh
                echo '  OS=$(uname -s)' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Install OS-specific dependencies' >> xdr_install.sh
                echo 'case $OS in' >> xdr_install.sh
                echo '  ubuntu|debian)' >> xdr_install.sh
                echo '    log "Detected Ubuntu/Debian system"' >> xdr_install.sh
                echo '    # Ubuntu doesnt need selinux-policy-devel' >> xdr_install.sh
                echo '    ;;' >> xdr_install.sh
                echo '  centos|rhel|fedora)' >> xdr_install.sh
                echo '    log "Detected CentOS/RHEL/Fedora system"' >> xdr_install.sh
                echo '    yum install selinux-policy-devel.noarch -y' >> xdr_install.sh
                echo '    ;;' >> xdr_install.sh
                echo '  *)' >> xdr_install.sh
                echo '    log "Unknown OS: $OS"' >> xdr_install.sh
                echo '    ;;' >> xdr_install.sh
                echo 'esac' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Function for logging' >> xdr_install.sh
                echo 'log() {' >> xdr_install.sh
                echo '  echo "[$(date '"'"'+%Y-%m-%d %H:%M:%S'"'"')] $1" | tee -a "$LOG_FILE"' >> xdr_install.sh
                echo '}' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Function to install AWS CLI if missing' >> xdr_install.sh
                echo 'ensure_aws_cli() {' >> xdr_install.sh
                echo '  if ! command -v aws &> /dev/null; then' >> xdr_install.sh
                echo '    log "AWS CLI not found, installing..."' >> xdr_install.sh
                echo '    cd /tmp' >> xdr_install.sh
                echo '    curl -s "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"' >> xdr_install.sh
                echo '    unzip -q awscliv2.zip' >> xdr_install.sh
                echo '    ./aws/install' >> xdr_install.sh
                echo '    rm -rf awscliv2.zip aws/' >> xdr_install.sh
                echo '    # Add to PATH for current session' >> xdr_install.sh
                echo '    export PATH="/usr/local/bin:$PATH"' >> xdr_install.sh
                echo '    if ! command -v aws &> /dev/null; then' >> xdr_install.sh
                echo '      log "ERROR: Failed to install AWS CLI"' >> xdr_install.sh
                echo '      return 1' >> xdr_install.sh
                echo '    fi' >> xdr_install.sh
                echo '    log "AWS CLI installed successfully"' >> xdr_install.sh
                echo '  else' >> xdr_install.sh
                echo '    log "AWS CLI found at: $(which aws)"' >> xdr_install.sh
                echo '  fi' >> xdr_install.sh
                echo '  return 0' >> xdr_install.sh
                echo '}' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Start installation process' >> xdr_install.sh
                echo 'log "Starting Cortex XDR installation"' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Ensure AWS CLI is available' >> xdr_install.sh
                echo 'ensure_aws_cli' >> xdr_install.sh
                echo 'if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '  exit 1' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Create temporary directory for download' >> xdr_install.sh
                echo 'TEMP_DIR=$(mktemp -d)' >> xdr_install.sh
                echo 'cd "$TEMP_DIR"' >> xdr_install.sh
                echo 'log "Working in temporary directory: $TEMP_DIR"' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Download the tar.gz file from S3' >> xdr_install.sh
                echo 'S3_FILE="$1"' >> xdr_install.sh
                echo 'FILENAME=$(basename "$S3_FILE")' >> xdr_install.sh
                echo 'log "Downloading $S3_FILE from S3"' >> xdr_install.sh
                echo 'aws s3 cp "s3://$S3_FILE" .' >> xdr_install.sh
                echo 'if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '  log "ERROR: Failed to download file from S3"' >> xdr_install.sh
                echo '  exit 1' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Extract the archive' >> xdr_install.sh
                echo 'log "Extracting $FILENAME"' >> xdr_install.sh
                echo 'tar -xzf "$FILENAME"' >> xdr_install.sh
                echo 'if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '  log "ERROR: Failed to extract archive"' >> xdr_install.sh
                echo '  exit 1' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo 'log "Archive extracted successfully"' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Create the /etc/panw directory if it doesn'"'"'t exist' >> xdr_install.sh
                echo 'if [ ! -d "/etc/panw" ]; then' >> xdr_install.sh
                echo '  log "Creating /etc/panw directory"' >> xdr_install.sh
                echo '  mkdir -p /etc/panw' >> xdr_install.sh
                echo '  if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '    log "ERROR: Failed to create /etc/panw directory"' >> xdr_install.sh
                echo '    exit 1' >> xdr_install.sh
                echo '  fi' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Find the cortex.conf file' >> xdr_install.sh
                echo 'CONF_FILE=$(find . -name "cortex.conf" | head -1)' >> xdr_install.sh
                echo 'if [ -n "$CONF_FILE" ]; then' >> xdr_install.sh
                echo '  log "Found configuration file: $CONF_FILE"' >> xdr_install.sh
                echo '  log "Copying $CONF_FILE to /etc/panw/"' >> xdr_install.sh
                echo '  cp "$CONF_FILE" /etc/panw/' >> xdr_install.sh
                echo '  if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '    log "ERROR: Failed to copy configuration file"' >> xdr_install.sh
                echo '    exit 1' >> xdr_install.sh
                echo '  fi' >> xdr_install.sh
                echo 'else' >> xdr_install.sh
                echo '  log "ERROR: Could not find cortex.conf file"' >> xdr_install.sh
                echo '  exit 1' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Find the installation script (cortex*sh)' >> xdr_install.sh
                echo 'INSTALL_SCRIPT=$(find . -name "cortex*sh" | head -1)' >> xdr_install.sh
                echo 'if [ -n "$INSTALL_SCRIPT" ]; then' >> xdr_install.sh
                echo '  log "Found installation script: $INSTALL_SCRIPT"' >> xdr_install.sh
                echo '  log "Setting executable permissions on $INSTALL_SCRIPT"' >> xdr_install.sh
                echo '  chmod +x "$INSTALL_SCRIPT"' >> xdr_install.sh
                echo '  if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '    log "ERROR: Failed to set executable permissions"' >> xdr_install.sh
                echo '    exit 1' >> xdr_install.sh
                echo '  fi' >> xdr_install.sh
                echo '  ' >> xdr_install.sh
                echo '  log "Executing installation script"' >> xdr_install.sh
                echo '  ./$INSTALL_SCRIPT' >> xdr_install.sh
                echo '  INSTALL_RESULT=$?' >> xdr_install.sh
                echo '  if [ $INSTALL_RESULT -eq 0 ]; then' >> xdr_install.sh
                echo '    log "Installation completed successfully"' >> xdr_install.sh
                echo '  else' >> xdr_install.sh
                echo '    log "ERROR: Installation failed with exit code $INSTALL_RESULT"' >> xdr_install.sh
                echo '    exit 1' >> xdr_install.sh
                echo '  fi' >> xdr_install.sh
                echo 'else' >> xdr_install.sh
                echo '  log "ERROR: Could not find installation script (cortex*sh)"' >> xdr_install.sh
                echo '  exit 1' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Clean up' >> xdr_install.sh
                echo 'log "Cleaning up temporary directory"' >> xdr_install.sh
                echo 'cd /' >> xdr_install.sh
                echo 'rm -rf "$TEMP_DIR"' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo 'log "Cortex XDR installation process completed"' >> xdr_install.sh
                echo 'exit 0' >> xdr_install.sh
                
                # Make the script executable
                chmod +x xdr_install.sh
                
                # Upload the script to S3
                aws s3 cp xdr_install.sh "s3://$S3_BUCKET/xdr_install.sh" || {
                  echo "::warning::Failed to upload XDR installation script to S3. XDR installation skipped."
                  echo "::notice::XDR Agent installation failed: Script upload error"
                  XDR_INSTALL_SUCCESS=false
                }
                
                if [ "$XDR_INSTALL_SUCCESS" = true ]; then
                  # Get both instance IDs using AWS CLI instead of Terraform
                  echo "Getting instance IDs using AWS CLI..."
                  
                  # Get App Instance ID (already available from env variable)
                  APP_INSTANCE_ID="${{ env.APP_INSTANCE_ID }}"
                  
                  # Get Jenkins Instance ID directly from AWS using tags
                  JENKINS_INSTANCE_ID=$(aws ec2 describe-instances \
                    --filters "Name=tag:Name,Values=${{ env.PROJECT_NAME }}-jenkins-instance" "Name=instance-state-name,Values=pending,running" \
                    --query "Reservations[*].Instances[*].[InstanceId]" \
                    --output text | head -n1)
                  
                  echo "App Instance ID: $APP_INSTANCE_ID"
                  echo "Jenkins Instance ID: $JENKINS_INSTANCE_ID"
                  
                  # Initialize status tracking
                  APP_AWS_CLI="Unknown"
                  APP_XDR="Not Attempted"
                  JENKINS_AWS_CLI="Unknown"
                  JENKINS_XDR="Not Attempted"
                  
                  # Check AWS CLI status on both instances
                  echo "Checking AWS CLI installation status..."
                  
                  # Check App instance
                  AWS_CHECK_CMD="command -v aws >/dev/null 2>&1 && aws --version || echo 'AWS CLI not found'"
                  APP_AWS_CHECK=$(aws ssm send-command \
                    --instance-ids "$APP_INSTANCE_ID" \
                    --document-name "AWS-RunShellScript" \
                    --parameters "commands=$AWS_CHECK_CMD" \
                    --query "Command.CommandId" \
                    --output text 2>/dev/null || echo "")
                  
                  if [ -n "$APP_AWS_CHECK" ]; then
                    sleep 3
                    APP_AWS_OUTPUT=$(aws ssm get-command-invocation \
                      --command-id "$APP_AWS_CHECK" \
                      --instance-id "$APP_INSTANCE_ID" \
                      --query "StandardOutputContent" \
                      --output text 2>/dev/null || echo "")
                    
                    if echo "$APP_AWS_OUTPUT" | grep -q "aws-cli"; then
                      APP_AWS_CLI="âœ… Installed"
                      echo "âœ… AWS CLI is installed on App instance"
                    else
                      APP_AWS_CLI="âŒ Not Found"
                      echo "âŒ AWS CLI not found on App instance"
                    fi
                  fi
                  
                  # Check Jenkins instance
                  JENKINS_AWS_CHECK=$(aws ssm send-command \
                    --instance-ids "$JENKINS_INSTANCE_ID" \
                    --document-name "AWS-RunShellScript" \
                    --parameters "commands=$AWS_CHECK_CMD" \
                    --query "Command.CommandId" \
                    --output text 2>/dev/null || echo "")
                  
                  if [ -n "$JENKINS_AWS_CHECK" ]; then
                    sleep 3
                    JENKINS_AWS_OUTPUT=$(aws ssm get-command-invocation \
                      --command-id "$JENKINS_AWS_CHECK" \
                      --instance-id "$JENKINS_INSTANCE_ID" \
                      --query "StandardOutputContent" \
                      --output text 2>/dev/null || echo "")
                    
                    if echo "$JENKINS_AWS_OUTPUT" | grep -q "aws-cli"; then
                      JENKINS_AWS_CLI="âœ… Installed"
                      echo "âœ… AWS CLI is installed on Jenkins instance"
                    else
                      JENKINS_AWS_CLI="âŒ Not Found"
                      echo "âŒ AWS CLI not found on Jenkins instance"
                    fi
                  fi
                  
                  # Install XDR on both instances
                  for INSTANCE_ID in "$APP_INSTANCE_ID" "$JENKINS_INSTANCE_ID"; do
                    # Skip if instance ID is empty
                    if [ -z "$INSTANCE_ID" ]; then
                      echo "::warning::Empty instance ID, skipping XDR installation for this instance"
                      continue
                    fi
                    
                    echo "Running XDR installation on instance $INSTANCE_ID..."

                    # Create the SSM command to download and run the installation script
                    XDR_COMMANDS='["aws s3 cp s3://'$S3_BUCKET'/xdr_install.sh /tmp/xdr_install.sh", "chmod +x /tmp/xdr_install.sh", "/tmp/xdr_install.sh '$S3_BUCKET'/'$TAR_FILENAME'"]'
                    
                    # Execute the installation via SSM
                    echo "Sending SSM command to instance $INSTANCE_ID..."
                    aws ssm send-command \
                      --instance-ids "$INSTANCE_ID" \
                      --document-name "AWS-RunShellScript" \
                      --parameters commands="$XDR_COMMANDS" \
                      --query "Command.CommandId" \
                      --output text > "ssm_command_id_${INSTANCE_ID}.txt" || {
                        echo "::warning::Failed to send SSM command to instance $INSTANCE_ID. XDR installation skipped."
                        echo "::notice::XDR Agent installation failed on instance $INSTANCE_ID: SSM command error"
                        continue
                      }
                    
                    # Get the command ID directly from output file
                    SSM_COMMAND_ID=$(cat "ssm_command_id_${INSTANCE_ID}.txt")
                    echo "Instance $INSTANCE_ID - SSM Command ID: $SSM_COMMAND_ID"
                    
                    # If the command ID is empty or invalid, the installation will be skipped
                    if [ -z "$SSM_COMMAND_ID" ] || [ ${#SSM_COMMAND_ID} -lt 36 ]; then
                      echo "::warning::Failed to get valid SSM Command ID for instance $INSTANCE_ID. XDR installation status unknown."
                      echo "::notice::XDR Agent installation failed on instance $INSTANCE_ID: Could not get valid command ID"
                    else
                      # Wait for the command to complete
                      echo "Waiting for the XDR installation to complete on instance $INSTANCE_ID..."
                      
                      # Initialize variables
                      SSM_STATUS="Pending"
                      MAX_RETRIES=7
                      COUNT=0
                      
                      # Loop until the command completes or times out
                      while [ "$SSM_STATUS" != "Success" ] && [ "$SSM_STATUS" != "Failed" ] && [ "$COUNT" -lt "$MAX_RETRIES" ]; do
                        # Get the command status
                        SSM_STATUS=$(aws ssm list-commands \
                          --command-id "$SSM_COMMAND_ID" \
                          --query "Commands[0].Status" \
                          --output text)
                        
                        echo "Instance $INSTANCE_ID - Attempt $COUNT/$MAX_RETRIES: Command status is $SSM_STATUS"
                        
                        if [ "$SSM_STATUS" == "Success" ]; then
                          echo "âœ… XDR installation on instance $INSTANCE_ID completed successfully."
                          if [ "$INSTANCE_ID" == "$APP_INSTANCE_ID" ]; then
                            APP_XDR="âœ… Installed"
                          else
                            JENKINS_XDR="âœ… Installed"
                          fi
                          break
                        elif [ "$SSM_STATUS" == "Failed" ]; then
                          echo "âš ï¸ XDR installation on instance $INSTANCE_ID encountered an issue. See logs for details."
                          echo "::warning::XDR installation failed on instance $INSTANCE_ID."
                          if [ "$INSTANCE_ID" == "$APP_INSTANCE_ID" ]; then
                            APP_XDR="âŒ Failed"
                          else
                            JENKINS_XDR="âŒ Failed"
                          fi
                          # Get the command output to understand the failure
                          aws ssm get-command-invocation \
                            --command-id "$SSM_COMMAND_ID" \
                            --instance-id "$INSTANCE_ID" \
                            --query "StandardOutputContent" \
                            --output text
                          aws ssm get-command-invocation \
                            --command-id "$SSM_COMMAND_ID" \
                            --instance-id "$INSTANCE_ID" \
                            --query "StandardErrorContent" \
                            --output text
                          break
                        fi
                        
                        # Increment counter and wait before checking again
                        COUNT=$((COUNT+1))
                        sleep 10
                      done
                      
                      if [ "$COUNT" -ge "$MAX_RETRIES" ]; then
                        echo "âš ï¸ Timed out waiting for XDR installation on instance $INSTANCE_ID to complete. Current status: $SSM_STATUS"
                        echo "::warning::Timed out waiting for XDR installation on instance $INSTANCE_ID to complete."
                        echo "::notice::XDR Agent installation status on instance $INSTANCE_ID: Timeout - final status unknown"
                      fi
                    fi
                  done
                fi
              fi
              
              # Export status variables for the deployment summary
              echo "APP_AWS_CLI=$APP_AWS_CLI" >> $GITHUB_ENV
              echo "APP_XDR=$APP_XDR" >> $GITHUB_ENV
              echo "JENKINS_AWS_CLI=$JENKINS_AWS_CLI" >> $GITHUB_ENV
              echo "JENKINS_XDR=$JENKINS_XDR" >> $GITHUB_ENV
            fi
          else
            echo "âš ï¸ No .tar.gz files found in xdr_install directory."
            echo "::notice::XDR Agent installation skipped: No .tar.gz files found"
            XDR_INSTALL_SUCCESS=false
          fi
        else
          echo "âš ï¸ xdr_install directory not found in the repository."
          echo "::notice::XDR Agent installation skipped: Directory not found"
          XDR_INSTALL_SUCCESS=false
        fi
        
        # Final installation status summary
        if [ "$XDR_INSTALL_SUCCESS" = true ]; then
          echo "::notice::Cortex XDR Agent installation completed successfully"
        else
          echo "::warning::Cortex XDR Agent installation did not complete successfully, but build will continue"
        fi

    - name: Output Deployment Info
      run: |
        echo "Application deployed successfully!"
        
        if [ -n "${{ env.APP_ALB_URL }}" ]; then
          echo "Application Load Balancer URL: ${{ env.APP_ALB_URL }}"
          echo "::notice title=âœ… Application URL::${{ env.APP_ALB_URL }}"
        else
          echo "Application Load Balancer URL: Not available"
        fi
        
        if [ -n "${{ env.ALB_DNS_NAME }}" ]; then
          echo "Application Load Balancer DNS: ${{ env.ALB_DNS_NAME }}"
        else
          echo "Application Load Balancer DNS: Not available"
        fi
        
        EC2_IP=$(aws ec2 describe-instances --instance-ids ${{ env.APP_INSTANCE_ID }} --query 'Reservations[0].Instances[0].PublicIpAddress' --output text 2>/dev/null)
        if [ -n "$EC2_IP" ] && [ "$EC2_IP" != "None" ]; then
          echo "Direct EC2 URL: http://$EC2_IP:80"
          echo "::notice title=ðŸ”— Direct EC2 Access::http://$EC2_IP:80"
        else
          echo "Direct EC2 URL: Not available"
        fi
        
        JENKINS_IP=$(aws ec2 describe-instances --filters 'Name=tag:Name,Values=${{ env.PROJECT_NAME }}-jenkins-instance' --query 'Reservations[0].Instances[0].PublicIpAddress' --output text 2>/dev/null)
        if [ -n "$JENKINS_IP" ] && [ "$JENKINS_IP" != "None" ]; then
          echo "Jenkins server should be accessible at: http://$JENKINS_IP:8080"
          echo "::notice title=ðŸ› ï¸ Jenkins Server::http://$JENKINS_IP:8080 (username: admin, password: admin123)"
        else
          echo "Jenkins server: Not available or still starting up"
        fi
        
        # Add a summary of all deployment URLs in Markdown format
        echo "## ðŸš€ Deployment URLs" >> $GITHUB_STEP_SUMMARY
        
        if [ -n "${{ env.APP_ALB_URL }}" ]; then
                      echo "* **Application (ALB)**: [${{ env.APP_ALB_URL }}](${{ env.APP_ALB_URL }})" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -n "$EC2_IP" ] && [ "$EC2_IP" != "None" ]; then
          echo "* **Application (Direct EC2)**: [http://$EC2_IP:80](http://$EC2_IP:80)" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -n "$JENKINS_IP" ] && [ "$JENKINS_IP" != "None" ]; then
          echo "* **Jenkins Server**: [http://$JENKINS_IP:8080](http://$JENKINS_IP:8080)" >> $GITHUB_STEP_SUMMARY
          echo "  * Username: \`admin\`" >> $GITHUB_STEP_SUMMARY
          echo "  * Password: \`admin123\`" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "* **Terraform State Bucket**: \`${{ env.TF_STATE_BUCKET }}\`" >> $GITHUB_STEP_SUMMARY
        
        # Add installation status summary
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## ðŸ“¦ Installation Status" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Instance | AWS CLI | XDR Agent |" >> $GITHUB_STEP_SUMMARY
        echo "|----------|---------|-----------|" >> $GITHUB_STEP_SUMMARY
        echo "| **App Instance** | ${APP_AWS_CLI:-Unknown} | ${APP_XDR:-Not Attempted} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Jenkins Instance** | ${JENKINS_AWS_CLI:-Unknown} | ${JENKINS_XDR:-Not Attempted} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "Terraform state is stored in S3 bucket: ${{ env.TF_STATE_BUCKET }}"
        echo "To destroy this infrastructure, use the Destroy Infrastructure workflow with this bucket name." 
